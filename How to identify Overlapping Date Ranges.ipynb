{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e10c8e81-a1c8-458b-b6aa-1d6e5a4fc19d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Problem Statement: \n",
    "\n",
    "Identify Overlapping Date Ranges\n",
    "\n",
    "You are given a dataset containing multiple records, each with a unique id, name, start_date, and end_date. The objective is to identify all pairs of records where the date ranges overlap. A date range is defined by the start_date and end_date fields.\n",
    "\n",
    "Conditions for Overlap:\n",
    "\n",
    "The start date of one record must be less than or equal to the end date of another record.\n",
    "The end date of one record must be greater than or equal to the start date of another record.\n",
    "The records being compared must be different (i.e., their id values must not match)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9ee64b1-bba8-427b-ae98-8a8c85df3fa5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>name</th><th>start_date</th><th>end_date</th></tr></thead><tbody><tr><td>1</td><td>Robert</td><td>2009-01-16</td><td>2009-01-20</td></tr><tr><td>2</td><td>JOHN</td><td>2010-06-24</td><td>2010-06-26</td></tr><tr><td>3</td><td>Robert</td><td>2009-01-18</td><td>2009-01-20</td></tr><tr><td>4</td><td>Emily</td><td>2012-03-12</td><td>2012-03-15</td></tr><tr><td>5</td><td>Sarah</td><td>2013-07-01</td><td>2013-07-05</td></tr><tr><td>6</td><td>JOHN</td><td>2011-09-10</td><td>2011-09-12</td></tr><tr><td>7</td><td>Emily</td><td>2015-11-20</td><td>2015-11-22</td></tr><tr><td>8</td><td>Michael</td><td>2018-02-14</td><td>2018-02-18</td></tr><tr><td>9</td><td>Sarah</td><td>2016-08-25</td><td>2016-08-29</td></tr><tr><td>10</td><td>Robert</td><td>2020-01-01</td><td>2020-01-05</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Robert",
         "2009-01-16",
         "2009-01-20"
        ],
        [
         2,
         "JOHN",
         "2010-06-24",
         "2010-06-26"
        ],
        [
         3,
         "Robert",
         "2009-01-18",
         "2009-01-20"
        ],
        [
         4,
         "Emily",
         "2012-03-12",
         "2012-03-15"
        ],
        [
         5,
         "Sarah",
         "2013-07-01",
         "2013-07-05"
        ],
        [
         6,
         "JOHN",
         "2011-09-10",
         "2011-09-12"
        ],
        [
         7,
         "Emily",
         "2015-11-20",
         "2015-11-22"
        ],
        [
         8,
         "Michael",
         "2018-02-14",
         "2018-02-18"
        ],
        [
         9,
         "Sarah",
         "2016-08-25",
         "2016-08-29"
        ],
        [
         10,
         "Robert",
         "2020-01-01",
         "2020-01-05"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "start_date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "end_date",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date  # Import to_date function\n",
    "\n",
    "# Extended sample data\n",
    "data = [\n",
    "    (1, \"Robert\", \"2009-01-16\", \"2009-01-20\"),\n",
    "    (2, \"JOHN\", \"2010-06-24\", \"2010-06-26\"),\n",
    "    (3, \"Robert\", \"2009-01-18\", \"2009-01-20\"),\n",
    "    (4, \"Emily\", \"2012-03-12\", \"2012-03-15\"),\n",
    "    (5, \"Sarah\", \"2013-07-01\", \"2013-07-05\"),\n",
    "    (6, \"JOHN\", \"2011-09-10\", \"2011-09-12\"),\n",
    "    (7, \"Emily\", \"2015-11-20\", \"2015-11-22\"),\n",
    "    (8, \"Michael\", \"2018-02-14\", \"2018-02-18\"),\n",
    "    (9, \"Sarah\", \"2016-08-25\", \"2016-08-29\"),\n",
    "    (10, \"Robert\", \"2020-01-01\", \"2020-01-05\"),\n",
    "]\n",
    "\n",
    "# Define schema\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"id\", IntegerType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"start_date\", StringType(), True),  # Temporarily StringType\n",
    "        StructField(\"end_date\", StringType(), True),  # Temporarily StringType\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Convert to DateType\n",
    "df = df.withColumn(\"start_date\", to_date(df[\"start_date\"], \"yyyy-MM-dd\")).withColumn(\n",
    "    \"end_date\", to_date(df[\"end_date\"], \"yyyy-MM-dd\")\n",
    ")\n",
    "\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1904a35-3f7e-46fa-8f15-2a7753646a42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id1</th><th>name1</th><th>start_date1</th><th>end_date1</th></tr></thead><tbody><tr><td>1</td><td>Robert</td><td>2009-01-16</td><td>2009-01-20</td></tr><tr><td>3</td><td>Robert</td><td>2009-01-18</td><td>2009-01-20</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Robert",
         "2009-01-16",
         "2009-01-20"
        ],
        [
         3,
         "Robert",
         "2009-01-18",
         "2009-01-20"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id1",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "name1",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "start_date1",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "end_date1",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Perform a self-join to compare each row with every other row\n",
    "overlap_df = df.alias(\"a\").join(\n",
    "    df.alias(\"b\"),\n",
    "    (\n",
    "        (col(\"a.id\") != col(\"b.id\"))\n",
    "        & (  # Exclude self-match\n",
    "            (col(\"a.start_date\") <= col(\"b.end_date\"))\n",
    "            & (  # Overlap condition 1\n",
    "                col(\"a.end_date\") >= col(\"b.start_date\")\n",
    "            )  # Overlap condition 2\n",
    "        )\n",
    "    ),\n",
    "    \"inner\",\n",
    ")\n",
    "\n",
    "# Select relevant columns for clarity\n",
    "overlap_df = overlap_df.select(\n",
    "    col(\"a.id\").alias(\"id1\"),\n",
    "    col(\"a.name\").alias(\"name1\"),\n",
    "    col(\"a.start_date\").alias(\"start_date1\"),\n",
    "    col(\"a.end_date\").alias(\"end_date1\"),\n",
    ")\n",
    "\n",
    "overlap_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00562cd9-44ea-42e3-9fa9-4d8293daaa2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register DataFrame as a temporary view\n",
    "df.createOrReplaceTempView(\"date_ranges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47c24bc0-89c3-44af-901c-d9f6101fb524",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----------+----------+\n|id1| name1|start_date1| end_date1|\n+---+------+-----------+----------+\n|  1|Robert| 2009-01-16|2009-01-20|\n|  3|Robert| 2009-01-18|2009-01-20|\n+---+------+-----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Write the SQL query to find overlapping date ranges\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    a.id AS id1, \n",
    "    a.name AS name1, \n",
    "    a.start_date AS start_date1, \n",
    "    a.end_date AS end_date1\n",
    "FROM date_ranges a\n",
    "JOIN date_ranges b\n",
    "ON a.id != b.id -- Exclude self-match\n",
    "AND a.start_date <= b.end_date -- Overlap condition 1\n",
    "AND a.end_date >= b.start_date -- Overlap condition 2\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "overlap_df_sql = spark.sql(query)\n",
    "\n",
    "# Show the results\n",
    "overlap_df_sql.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f689173-33b0-4930-9f2c-f15a2ba28eab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Explanation of the SQL Query\n",
    "\n",
    "Self-Join: The date_ranges table is joined with itself to compare every row with every other row.\n",
    "Excluding Self-Match: The condition a.id != b.id ensures a record is not compared with itself.\n",
    "\n",
    "Overlap Conditions:\n",
    "\n",
    "a.start_date <= b.end_date: The start date of one range is less than or equal to the end date of the other.\n",
    "a.end_date >= b.start_date: The end date of one range is greater than or equal to the start date of the other.\n",
    "This approach produces the same results as the PySpark DataFrame method but allows you to leverage Spark SQL's syntax."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "xml to array",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
