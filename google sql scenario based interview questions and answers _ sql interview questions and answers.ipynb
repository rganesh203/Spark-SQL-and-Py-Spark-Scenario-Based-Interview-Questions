{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ac13b74-798f-4940-a80e-d01fd667bd29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Problem Statement:\n",
    "\n",
    "Here have a dataset (google_files) containing a column content with text data, where each row represents a document. Your goal is to:\n",
    "\n",
    "Extract individual words from the content column.\n",
    "Count the occurrences of specific target words (e.g., 'SQL' and 'PySpark') across the entire dataset.\n",
    "Output the word and its corresponding count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6bd4e22-740c-4e6c-912a-9e4c8e1c0e28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>file_name</th><th>content</th></tr></thead><tbody><tr><td>file1.txt</td><td>Google Uses SQL</td></tr><tr><td>file2.txt</td><td>Google Uses SQL and PySpark to fetch the Data</td></tr><tr><td>file3.txt</td><td>Google Uses NoSQL DataBase and PySpark for processing of Data</td></tr><tr><td>file4.txt</td><td>Writing code in PySpark is very easy</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "file1.txt",
         "Google Uses SQL"
        ],
        [
         "file2.txt",
         "Google Uses SQL and PySpark to fetch the Data"
        ],
        [
         "file3.txt",
         "Google Uses NoSQL DataBase and PySpark for processing of Data"
        ],
        [
         "file4.txt",
         "Writing code in PySpark is very easy"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "file_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "content",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the data for the table\n",
    "data = [\n",
    "    (\"file1.txt\", \"Google Uses SQL\"),\n",
    "    (\"file2.txt\", \"Google Uses SQL and PySpark to fetch the Data\"),\n",
    "    (\"file3.txt\", \"Google Uses NoSQL DataBase and PySpark for processing of Data\"),\n",
    "    (\"file4.txt\", \"Writing code in PySpark is very easy\"),\n",
    "]\n",
    "\n",
    "# Define the schema\n",
    "columns = [\"file_name\", \"content\"]\n",
    "\n",
    "# Create a DataFrame\n",
    "google_files_df = spark.createDataFrame(data, schema=columns)\n",
    "\n",
    "# display the DataFrame\n",
    "google_files_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1952351f-5519-4620-b0f5-7c7946a0900f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "google_files_df.createOrReplaceTempView(\"google_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23d8d4de-7192-484f-a9a9-58b58e545a8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>word</th><th>word_count</th></tr></thead><tbody><tr><td>SQL</td><td>2</td></tr><tr><td>PySpark</td><td>3</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "SQL",
         2
        ],
        [
         "PySpark",
         3
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "word",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "word_count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, split, explode, count\n",
    "\n",
    "# Explode the content into words\n",
    "words_df = google_files_df.withColumn(\"word\", explode(split(col(\"content\"), \" \")))\n",
    "\n",
    "# Filter the words of interest ('SQL' and 'PySpark') and count them\n",
    "result_df = (\n",
    "    words_df.filter(col(\"word\").isin(\"SQL\", \"PySpark\"))\n",
    "    .groupBy(\"word\")\n",
    "    .agg(count(\"word\").alias(\"word_count\"))\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "result_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1c3564a-34d1-4e98-9caf-9d01c3064fdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>word</th></tr></thead><tbody><tr><td>Google</td></tr><tr><td>Uses</td></tr><tr><td>SQL</td></tr><tr><td>Google</td></tr><tr><td>Uses</td></tr><tr><td>SQL</td></tr><tr><td>and</td></tr><tr><td>PySpark</td></tr><tr><td>to</td></tr><tr><td>fetch</td></tr><tr><td>the</td></tr><tr><td>Data</td></tr><tr><td>Google</td></tr><tr><td>Uses</td></tr><tr><td>NoSQL</td></tr><tr><td>DataBase</td></tr><tr><td>and</td></tr><tr><td>PySpark</td></tr><tr><td>for</td></tr><tr><td>processing</td></tr><tr><td>of</td></tr><tr><td>Data</td></tr><tr><td>Writing</td></tr><tr><td>code</td></tr><tr><td>in</td></tr><tr><td>PySpark</td></tr><tr><td>is</td></tr><tr><td>very</td></tr><tr><td>easy</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Google"
        ],
        [
         "Uses"
        ],
        [
         "SQL"
        ],
        [
         "Google"
        ],
        [
         "Uses"
        ],
        [
         "SQL"
        ],
        [
         "and"
        ],
        [
         "PySpark"
        ],
        [
         "to"
        ],
        [
         "fetch"
        ],
        [
         "the"
        ],
        [
         "Data"
        ],
        [
         "Google"
        ],
        [
         "Uses"
        ],
        [
         "NoSQL"
        ],
        [
         "DataBase"
        ],
        [
         "and"
        ],
        [
         "PySpark"
        ],
        [
         "for"
        ],
        [
         "processing"
        ],
        [
         "of"
        ],
        [
         "Data"
        ],
        [
         "Writing"
        ],
        [
         "code"
        ],
        [
         "in"
        ],
        [
         "PySpark"
        ],
        [
         "is"
        ],
        [
         "very"
        ],
        [
         "easy"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "word",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  EXPLODE(SPLIT(content, ' ')) AS word\n",
    "FROM\n",
    "  google_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "005b8844-c34b-45ca-bc30-68841f8942d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>word</th><th>word_count</th></tr></thead><tbody><tr><td>SQL</td><td>2</td></tr><tr><td>PySpark</td><td>3</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "SQL",
         2
        ],
        [
         "PySpark",
         3
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "word",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "word_count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "WITH cte AS (\n",
    "  SELECT\n",
    "    EXPLODE(SPLIT(content, ' ')) AS word\n",
    "  FROM\n",
    "    google_files\n",
    ")\n",
    "SELECT\n",
    "  word,\n",
    "  COUNT(word) AS word_count\n",
    "FROM\n",
    "  cte\n",
    "WHERE\n",
    "  word IN ('SQL', 'PySpark')\n",
    "GROUP BY\n",
    "  word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d359d889-56b2-4f0b-a153-91839a3a8d8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Explanation:\n",
    "\n",
    "split(content, ' '): Splits the string content into an array of words, based on the space character.\n",
    "\n",
    "explode(split(...)): Converts the array of words into individual rows (one word per row).\n",
    "\n",
    "WHERE word IN (...): Filters the rows for specific words ('SQL', 'PySpark').\n",
    "\n",
    "GROUP BY word: Groups the filtered words and counts occurrences."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1192579866172699,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "google sql scenario based interview questions and answers | sql interview questions and answers",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
